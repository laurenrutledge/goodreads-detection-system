{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# This File Produces a Substantiveness Score for Book Reviews. \n",
    "### Goal: Score reviews 0-5 based on how detailed/informative they are"
   ],
   "id": "57b0b996ea8f5050"
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-22T22:37:30.208912Z",
     "start_time": "2025-07-22T22:37:01.516611Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Install required NLP libraries\n",
    "!pip install nltk spacy\n",
    "\n",
    "# Install / download spaCy English model\n",
    "!python -m spacy download en_core_web_sm"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /opt/anaconda3/envs/goodreads-nlp/lib/python3.10/site-packages (3.9.1)\r\n",
      "Requirement already satisfied: spacy in /opt/anaconda3/envs/goodreads-nlp/lib/python3.10/site-packages (3.8.7)\r\n",
      "Requirement already satisfied: click in /opt/anaconda3/envs/goodreads-nlp/lib/python3.10/site-packages (from nltk) (8.2.1)\r\n",
      "Requirement already satisfied: joblib in /opt/anaconda3/envs/goodreads-nlp/lib/python3.10/site-packages (from nltk) (1.5.1)\r\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/anaconda3/envs/goodreads-nlp/lib/python3.10/site-packages (from nltk) (2024.11.6)\r\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/envs/goodreads-nlp/lib/python3.10/site-packages (from nltk) (4.67.1)\r\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/anaconda3/envs/goodreads-nlp/lib/python3.10/site-packages (from spacy) (3.0.12)\r\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/anaconda3/envs/goodreads-nlp/lib/python3.10/site-packages (from spacy) (1.0.5)\r\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/anaconda3/envs/goodreads-nlp/lib/python3.10/site-packages (from spacy) (1.0.13)\r\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/anaconda3/envs/goodreads-nlp/lib/python3.10/site-packages (from spacy) (2.0.11)\r\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/anaconda3/envs/goodreads-nlp/lib/python3.10/site-packages (from spacy) (3.0.10)\r\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /opt/anaconda3/envs/goodreads-nlp/lib/python3.10/site-packages (from spacy) (8.3.4)\r\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/anaconda3/envs/goodreads-nlp/lib/python3.10/site-packages (from spacy) (1.1.3)\r\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/anaconda3/envs/goodreads-nlp/lib/python3.10/site-packages (from spacy) (2.5.1)\r\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/anaconda3/envs/goodreads-nlp/lib/python3.10/site-packages (from spacy) (2.0.10)\r\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /opt/anaconda3/envs/goodreads-nlp/lib/python3.10/site-packages (from spacy) (0.4.1)\r\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /opt/anaconda3/envs/goodreads-nlp/lib/python3.10/site-packages (from spacy) (0.16.0)\r\n",
      "Requirement already satisfied: numpy>=1.19.0 in /opt/anaconda3/envs/goodreads-nlp/lib/python3.10/site-packages (from spacy) (1.26.4)\r\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/anaconda3/envs/goodreads-nlp/lib/python3.10/site-packages (from spacy) (2.32.4)\r\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /opt/anaconda3/envs/goodreads-nlp/lib/python3.10/site-packages (from spacy) (2.11.7)\r\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/envs/goodreads-nlp/lib/python3.10/site-packages (from spacy) (3.1.6)\r\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/envs/goodreads-nlp/lib/python3.10/site-packages (from spacy) (78.1.1)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/envs/goodreads-nlp/lib/python3.10/site-packages (from spacy) (24.2)\r\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/anaconda3/envs/goodreads-nlp/lib/python3.10/site-packages (from spacy) (3.5.0)\r\n",
      "Requirement already satisfied: language-data>=1.2 in /opt/anaconda3/envs/goodreads-nlp/lib/python3.10/site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\r\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/anaconda3/envs/goodreads-nlp/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /opt/anaconda3/envs/goodreads-nlp/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.33.2)\r\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /opt/anaconda3/envs/goodreads-nlp/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\r\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /opt/anaconda3/envs/goodreads-nlp/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.1)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/anaconda3/envs/goodreads-nlp/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/envs/goodreads-nlp/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/goodreads-nlp/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.5.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/goodreads-nlp/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.7.14)\r\n",
      "Requirement already satisfied: blis<1.3.0,>=1.2.0 in /opt/anaconda3/envs/goodreads-nlp/lib/python3.10/site-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.2.1)\r\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/anaconda3/envs/goodreads-nlp/lib/python3.10/site-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\r\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /opt/anaconda3/envs/goodreads-nlp/lib/python3.10/site-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\r\n",
      "Requirement already satisfied: rich>=10.11.0 in /opt/anaconda3/envs/goodreads-nlp/lib/python3.10/site-packages (from typer<1.0.0,>=0.3.0->spacy) (14.0.0)\r\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /opt/anaconda3/envs/goodreads-nlp/lib/python3.10/site-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.21.1)\r\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /opt/anaconda3/envs/goodreads-nlp/lib/python3.10/site-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.3.0.post1)\r\n",
      "Requirement already satisfied: wrapt in /opt/anaconda3/envs/goodreads-nlp/lib/python3.10/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.2)\r\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in /opt/anaconda3/envs/goodreads-nlp/lib/python3.10/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\r\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/anaconda3/envs/goodreads-nlp/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\r\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/anaconda3/envs/goodreads-nlp/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.19.1)\r\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/anaconda3/envs/goodreads-nlp/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/envs/goodreads-nlp/lib/python3.10/site-packages (from jinja2->spacy) (3.0.2)\r\n",
      "/opt/anaconda3/envs/goodreads-nlp/lib/python3.10/site-packages/requests/__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\r\n",
      "  warnings.warn(\r\n",
      "Collecting en-core-web-sm==3.8.0\r\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m12.8/12.8 MB\u001B[0m \u001B[31m476.2 kB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:02\u001B[0m\r\n",
      "\u001B[?25h\u001B[33mWARNING: Error parsing dependencies of regex: [Errno 2] No such file or directory: '/opt/anaconda3/envs/goodreads-nlp/lib/python3.10/site-packages/regex-2024.11.6.dist-info/METADATA'\u001B[0m\u001B[33m\r\n",
      "\u001B[0m\u001B[33mWARNING: Error parsing dependencies of tqdm: [Errno 2] No such file or directory: '/opt/anaconda3/envs/goodreads-nlp/lib/python3.10/site-packages/tqdm-4.67.1.dist-info/METADATA'\u001B[0m\u001B[33m\r\n",
      "\u001B[0m\u001B[38;5;2m✔ Download and installation successful\u001B[0m\r\n",
      "You can now load the package via spacy.load('en_core_web_sm')\r\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Imports and Setup",
   "id": "67db76b92a390eda"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T07:54:49.728160Z",
     "start_time": "2025-07-24T07:54:48.940951Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "import spacy\n",
    "\n",
    "# Download NLTK data \n",
    "nltk.download('punkt')\n",
    "\n",
    "# Load spaCy's English model\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ],
   "id": "20f2eb1ad5abcce3",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/laurenrutledge/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Read in Cleaned Data CSV:",
   "id": "5a2a0976234f51a5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T23:46:35.757563Z",
     "start_time": "2025-07-23T23:46:27.761955Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = pd.read_csv('datasets/processed/goodreads_reviews_mystery_thriller_crime_with_links_flag.csv')\n",
    "\n",
    "print(\"Post-Data Clean row count:\", len(df),\"\\n\")\n",
    "print(df.head())\n"
   ],
   "id": "70ef94db89a1bf4a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post-Data Clean row count: 1685280 \n",
      "\n",
      "                            user_id                         review_id  \\\n",
      "0  8842281e1d1347389f2ab93d60773d4d  5e212a62bced17b4dbe41150e5bb9037   \n",
      "1  8842281e1d1347389f2ab93d60773d4d  2ede853b14dc4583f96cf5d120af636f   \n",
      "2  8842281e1d1347389f2ab93d60773d4d  022bb6daffa49adc27f6b20b6ebeb37d   \n",
      "3  8842281e1d1347389f2ab93d60773d4d  0e317947e1fd341f573192111bb2921d   \n",
      "4  8842281e1d1347389f2ab93d60773d4d  4276918357312212384ac6415ceb9159   \n",
      "\n",
      "                                         review_text  rating  \\\n",
      "0  I haven't read a fun mystery book in a while a...       3   \n",
      "1  A fun, fast paced science fiction thriller. I ...       3   \n",
      "2  An amazing and unique creation: JJ Abrams and ...       4   \n",
      "3  The Name of the Rose is a thrilling Dan Brown-...       3   \n",
      "4  ** spoiler alert ** \\n Hooked me equally as we...       3   \n",
      "\n",
      "                       date_added  n_votes  contains_link  \n",
      "0  Mon Jul 24 02:48:17 -0700 2017        6          False  \n",
      "1  Tue Nov 15 11:29:22 -0800 2016       22          False  \n",
      "2  Wed Mar 26 13:51:30 -0700 2014        7          False  \n",
      "3  Wed Sep 08 01:22:27 -0700 2010       17          False  \n",
      "4  Mon Mar 29 15:54:28 -0700 2010        1          False  \n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Define NLP Feature Functions",
   "id": "60929bc4213b33f6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T22:41:25.815451Z",
     "start_time": "2025-07-22T22:41:25.813411Z"
    }
   },
   "cell_type": "code",
   "source": "from nltk.tokenize import sent_tokenize, word_tokenize",
   "id": "c4b3ef912e503ff1",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Count Sentences in Text Review (NLTK)",
   "id": "8293dc25d6493504"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T23:48:04.107628Z",
     "start_time": "2025-07-23T23:46:39.465419Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Sentence count\n",
    "def count_sentences(text):\n",
    "    return len(sent_tokenize(text))\n",
    "\n",
    "# Apply NLTK-based features\n",
    "df['sentence_count'] = df['review_text'].apply(count_sentences)"
   ],
   "id": "25991fbeb470f71c",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Count Words in Text Review (NLTK)",
   "id": "d3bb3edaf675a0da"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T00:12:13.836383Z",
     "start_time": "2025-07-24T00:02:57.312402Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Word count\n",
    "def count_words(text):\n",
    "    return len(word_tokenize(text))\n",
    "\n",
    "df['word_count'] = df['review_text'].apply(count_words)"
   ],
   "id": "220831df427c62ae",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Determine Average Words per Sentence in Text Review",
   "id": "b54fb19fb151bc56"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T23:58:28.400976Z",
     "start_time": "2025-07-23T23:48:08.056582Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Average words per sentence\n",
    "def avg_words_per_sentence(text):\n",
    "    s = count_sentences(text)\n",
    "    w = count_words(text)\n",
    "    return (w / s) if s > 0 else 0\n",
    "\n",
    "df['avg_words_per_sentence'] = df['review_text'].apply(avg_words_per_sentence)"
   ],
   "id": "5a653c377c67c644",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Compute Lexical Diversity Score Per Review \n",
    "#### Reviews with higher diversity tend to use a richer vocabulary and be more detailed/informative."
   ],
   "id": "f595f7ada92e7d48"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T00:21:44.700701Z",
     "start_time": "2025-07-24T00:12:22.868067Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Lexical diversity (type-token ratio = number of unique words / total # of words\n",
    "# NLTK’s tokenizer splits text into individual tokens (words, punctuation, etc.).\n",
    "# If output is close to 1 = very diverse vocabulary (most words are unique)\n",
    "# If output is closer to 0 = lots of repetition in vocabulary \n",
    "\n",
    "def lexical_diversity(text):\n",
    "    \n",
    "    # Removes numbers and punctuation, lowercase everything \n",
    "    words = [w.lower() for w in word_tokenize(text) if w.isalpha()]\n",
    "    \n",
    "    # Set removes duplicates, returns \n",
    "    return len(set(words)) / len(words) if words else 0\n",
    "\n",
    "df['lexical_diversity'] = df['review_text'].apply(lexical_diversity)"
   ],
   "id": "6f6899f5b94eda47",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Determine whether a name (doesn't matter if it's a character or the author) is in the Review's Text",
   "id": "93c0efa6286dd4cf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T20:39:02.944090Z",
     "start_time": "2025-07-23T06:58:53.713169Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "2df66c907ed540ab",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T00:21:59.623222Z",
     "start_time": "2025-07-24T00:21:59.617538Z"
    }
   },
   "cell_type": "code",
   "source": "print(df.head())",
   "id": "c7fa3b7f83036569",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            user_id                         review_id  \\\n",
      "0  8842281e1d1347389f2ab93d60773d4d  5e212a62bced17b4dbe41150e5bb9037   \n",
      "1  8842281e1d1347389f2ab93d60773d4d  2ede853b14dc4583f96cf5d120af636f   \n",
      "2  8842281e1d1347389f2ab93d60773d4d  022bb6daffa49adc27f6b20b6ebeb37d   \n",
      "3  8842281e1d1347389f2ab93d60773d4d  0e317947e1fd341f573192111bb2921d   \n",
      "4  8842281e1d1347389f2ab93d60773d4d  4276918357312212384ac6415ceb9159   \n",
      "\n",
      "                                         review_text  rating  \\\n",
      "0  I haven't read a fun mystery book in a while a...       3   \n",
      "1  A fun, fast paced science fiction thriller. I ...       3   \n",
      "2  An amazing and unique creation: JJ Abrams and ...       4   \n",
      "3  The Name of the Rose is a thrilling Dan Brown-...       3   \n",
      "4  ** spoiler alert ** \\n Hooked me equally as we...       3   \n",
      "\n",
      "                       date_added  n_votes  contains_link  sentence_count  \\\n",
      "0  Mon Jul 24 02:48:17 -0700 2017        6          False               7   \n",
      "1  Tue Nov 15 11:29:22 -0800 2016       22          False              35   \n",
      "2  Wed Mar 26 13:51:30 -0700 2014        7          False              23   \n",
      "3  Wed Sep 08 01:22:27 -0700 2010       17          False              21   \n",
      "4  Mon Mar 29 15:54:28 -0700 2010        1          False               5   \n",
      "\n",
      "   avg_words_per_sentence  word_count  lexical_diversity  \n",
      "0               14.142857          99           0.705882  \n",
      "1               15.485714         542           0.486900  \n",
      "2               23.478261         540           0.486141  \n",
      "3               19.904762         418           0.556452  \n",
      "4               18.400000          92           0.759494  \n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": " ",
   "id": "42f486199e9e63f2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Save to Substantiveness csv for futher processesing",
   "id": "732590407af466e6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T00:22:22.556305Z",
     "start_time": "2025-07-24T00:22:11.144699Z"
    }
   },
   "cell_type": "code",
   "source": [
    "output_path = \"datasets/processed/goodreads_reviews_with_nlp_features_substantiveness_v2.csv\"\n",
    "\n",
    "df.to_csv(output_path, index=False)"
   ],
   "id": "3f0306b05fc4410d",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "input_path_2 = \"datasets/processed/goodreads_reviews_with_nlp_features_substantiveness_v2.csv\"\n",
    "\n",
    "pd.read_csv(input_path_2)"
   ],
   "id": "ecafc1e91fafc3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "8acce3f3f3d26586"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Named Entity Recognition with spaCy for people only\n",
    "def mentions_person(text):\n",
    "    \"\"\"\n",
    "    Returns 1 if the review mentions at least one person's name (spaCy PERSON entity),\n",
    "    otherwise returns 0.\n",
    "    \"\"\"\n",
    "    doc = nlp(text)\n",
    "    return int(any(ent.label_ == \"PERSON\" for ent in doc.ents))\n",
    "\n",
    "df['mentions_person'] = df['review_text'].apply(mentions_person)"
   ],
   "id": "7790bfa17d4e61fc"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
